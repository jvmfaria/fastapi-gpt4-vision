from fastapi import FastAPI, UploadFile, File, HTTPException
from fastapi.responses import JSONResponse
import base64
import os
import json
import re
from datetime import datetime
from dotenv import load_dotenv
from openai import OpenAI

# Carrega vari√°veis do ambiente
load_dotenv()

client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
app = FastAPI()

BASE_DIR = os.getenv("BASE_DIR", "./app/caracteristicas")
FOTOS_BASE_URL = "https://raw.githubusercontent.com/jvmfaria/fastapi-gpt4-vision/main/app/fotos"

TRA√áOS = ["esquizoide", "masoquista", "oral", "psicopata", "rigido"]
PARTES = ["cabeca", "olhos", "boca", "tronco", "quadril", "pernas"]

def carregar_caracteristicas():
    arquivos = {traco: f"{traco}.txt" for traco in TRA√áOS}
    conteudos = []
    for traco, nome_arquivo in arquivos.items():
        caminho = os.path.join(BASE_DIR, nome_arquivo)
        if os.path.exists(caminho):
            with open(caminho, "r", encoding="utf-8") as f:
                conteudos.append(f"{traco.upper()}:\n{f.read().strip()}\n")
    return "\n".join(conteudos)

CARACTERISTICAS_TEXTO = carregar_caracteristicas()

def file_to_data_url(file: UploadFile) -> str:
    if file.content_type not in ["image/jpeg", "image/png"]:
        raise HTTPException(status_code=400, detail="Formato de imagem n√£o suportado.")
    content = file.file.read()
    if len(content) > 5 * 1024 * 1024:
        raise HTTPException(status_code=400, detail="Arquivo de imagem excede 5MB.")
    encoded = base64.b64encode(content).decode("utf-8")
    return f"data:{file.content_type};base64,{encoded}"

def formatar_mensagem(dados):
    mensagem = ["üìä *An√°lise corporal completa por regi√£o*\n"]
    for parte in PARTES:
        bloco = dados.get(parte)
        if isinstance(bloco, dict):
            mensagem.append(f"\n*{parte.capitalize()}*")
            for traco in TRA√áOS:
                ponto = bloco.get(traco, 0)
                explicacao = bloco.get("explicacao", {})
                justificativa = explicacao.get(traco, "")
                mensagem.append(f"‚Ä¢ {traco.capitalize()}: {ponto} ‚Äî {justificativa}")
    mensagem.append("\nüß† *Total por Tra√ßo*")
    for traco in TRA√áOS:
        total = dados.get("soma_total_por_traco", {}).get(traco, 0)
        mensagem.append(f"‚Ä¢ {traco.capitalize()}: {total}")
    mensagem.append("\nüìå *Metodologia*: lia.ai!")
    return "\n".join(mensagem)

def distribuicoes_iguais(dados):
    distros = set()
    for parte in PARTES:
        bloco = dados.get(parte, {})
        dist = tuple(bloco.get(traco, 0) for traco in TRA√áOS)
        if dist in distros:
            return True
        distros.add(dist)
    return False

def normalizar_justificativas(dados):
    for parte in PARTES:
        bloco = dados.get(parte, {})
        explicacoes = bloco.get("explicacao", {})
        for traco, texto in explicacoes.items():
            texto = texto.strip().capitalize()
            if not texto.endswith("."):
                texto += "."
            explicacoes[traco] = texto
    return dados

def comparar_com_historico(dados_atuais, historico):
    comparacao = {}
    for traco in TRA√áOS:
        atual = dados_atuais.get("soma_total_por_traco", {}).get(traco, 0)
        anterior = historico.get("soma_total_por_traco", {}).get(traco, 0)
        comparacao[traco] = {
            "anterior": anterior,
            "atual": atual,
            "diferenca": atual - anterior
        }
    return comparacao

def construir_dados_classificacao(resultado: dict):
    totais = resultado.get("soma_total_por_traco", {})
    tracos_ordenados = sorted(totais.items(), key=lambda x: x[1], reverse=True)
    tracos_dominantes = [traco for traco, _ in tracos_ordenados[:3]]

    explicacoes = []
    for parte in PARTES:
        explicacao = resultado.get(parte, {}).get("explicacao", {})
        for traco in tracos_dominantes:
            if traco in explicacao:
                explicacoes.append(explicacao[traco])

    return {
        "tracos": tracos_dominantes,
        "dores": ["car√™ncia emocional", "necessidade de controle", "medo de rejei√ß√£o"],
        "recursos": ["capacidade de se adaptar", "empatia", "autopercep√ß√£o corporal"],
        "padroes_dependencia": ["busca constante por aprova√ß√£o", "medo de romper v√≠nculos afetivos"],
        "escolhas_inconscientes": [{
            "decisao": "reprimir vontades para manter v√≠nculos",
            "origem": "experi√™ncias infantis de rejei√ß√£o emocional"
        }],
        "impactos": ["tens√µes no t√≥rax e mand√≠bula", "bloqueios na express√£o emocional"]
    }

def gerar_prompt_relatorio(dados_classificacao, nome_cliente, data_atendimento, genero_cliente):
    pronome = "o" if genero_cliente.lower() == "masculino" else "a"
    artigo = "do" if genero_cliente.lower() == "masculino" else "da"

    tracos = dados_classificacao.get("tracos", [])
    dores = dados_classificacao.get("dores", [])
    recursos = dados_classificacao.get("recursos", [])
    padroes_dependencia = dados_classificacao.get("padroes_dependencia", [])
    escolhas_inconscientes = dados_classificacao.get("escolhas_inconscientes", [])
    impactos = dados_classificacao.get("impactos", [])

    return f"""
Voc√™ √© a assistente Lia ‚Äì Linguagem Integrativa de Autoconhecimento, da Corphus.

Sua tarefa √© gerar um relat√≥rio completo, humanizado e terap√™utico de an√°lise corporal no formato JSON, com base na psicologia reichiana, bioenerg√©tica e leitura corporal.

‚ö†Ô∏è O resultado deve ser um objeto JSON estruturado com os seguintes campos, todos preenchidos com profundidade, empatia e linguagem acolhedora. 

Considere o hist√≥rico emocional, padr√µes inconscientes e a estrutura corporal de {nome_cliente}, respeitando sua trajet√≥ria √∫nica. Adapte a linguagem de acordo com o g√™nero: utilize formas no feminino se for mulher e no masculino se for homem.

Responda apenas com o objeto JSON, conforme o modelo abaixo:

```json
{{
  "cabecalho": {{
    "nome_cliente": "{nome_cliente}",
    "data_atendimento": "{data_atendimento}",
    "nome_analista": "M√°rcio Concei√ß√£o",
    "titulo": "Relat√≥rio de An√°lise da Sua Hist√≥ria"
  }},
  "objetivo": "Descreva o prop√≥sito central deste processo terap√™utico para {pronome} cliente...",
  "resumo_inicial": "{nome_cliente}, a sua hist√≥ria revela...",
  "dores_e_recursos": {{
    "dores": {json.dumps(dores)},
    "recursos": {json.dumps(recursos)}
  }},
  "tracos_que_explicam": "Os principais tra√ßos que influenciam {artigo} cliente s√£o: {', '.join(tracos)}...",
  "padroes_dependencia_emocional": {json.dumps(padroes_dependencia)},
  "escolhas_inconscientes": [
    {{
      "decisao": "{escolhas_inconscientes[0]['decisao'] if escolhas_inconscientes else ''}",
      "origem": "{escolhas_inconscientes[0]['origem'] if escolhas_inconscientes else ''}"
    }}
  ],
  "impactos_das_dores": {json.dumps(impactos)},
  "virada_de_chave": "Apresente o ponto de virada mais significativo...",
  "proximos_passos": ["Sugira caminhos terap√™uticos..."],
  "acoes_praticas": [
    {{
      "oque": "Indique uma a√ß√£o concreta...",
      "como": "Explique como ela pode ser feita...",
      "porque": "Justifique o impacto positivo..."
    }}
  ],
  "conclusao": "Finalize com uma mensagem que reconhe√ßa..."
}}
```"""

@app.post("/classificar")
async def classificar():
    try:
        frente_url = f"{FOTOS_BASE_URL}/imagem_frente.png"
        lado_url = f"{FOTOS_BASE_URL}/imagem_lado.png"
        costas_url = f"{FOTOS_BASE_URL}/imagem_costas.png"

        prompt_instrucoes = """
Voc√™ √© um analista reichiano altamente experiente.

Abaixo est√£o as descri√ß√µes referenciais completas de cada tra√ßo de car√°ter, detalhadas por parte do corpo:

<<CARACTERISTICAS>>

Sua tarefa √© analisar cuidadosamente as imagens corporais fornecidas (frente, lado e costas)...

Apenas o JSON. Nada mais.
""".replace("<<CARACTERISTICAS>>", CARACTERISTICAS_TEXTO)

        response = client.chat.completions.create(
            model="gpt-4-turbo",
            messages=[
                {"role": "system", "content": "Voc√™ √© um analista reichiano altamente especialista em linguagem corporal."},
                {"role": "user", "content": prompt_instrucoes},
                {"role": "user", "content": [
                    {"type": "text", "text": "Imagem de frente:"},
                    {"type": "image_url", "image_url": {"url": frente_url}},
                    {"type": "text", "text": "Imagem de lateral:"},
                    {"type": "image_url", "image_url": {"url": lado_url}},
                    {"type": "text", "text": "Imagem de costas:"},
                    {"type": "image_url", "image_url": {"url": costas_url}}
                ]}
            ],
            temperature=0,
            max_tokens=2500
        )

        raw = response.choices[0].message.content or ""
        match = re.search(r"\{[\s\S]*\}", raw)
        if not match:
            raise ValueError(f"Falha ao localizar JSON na resposta:\n{raw}")
        resultado = json.loads(match.group(0))

        for parte in PARTES:
            bloco = resultado.get(parte)
            if not bloco:
                raise ValueError(f"Parte '{parte}' ausente no resultado.")
            if sum(bloco.get(traco, 0) for traco in TRA√áOS) != 10:
                raise ValueError(f"Soma dos tra√ßos em '{parte}' deve ser 10.")
            if "explicacao" not in bloco:
                raise ValueError(f"Faltando explica√ß√£o na parte '{parte}'.")

        mensagem = formatar_mensagem(resultado)
        return {"resultado": resultado, "mensagem": mensagem}

    except Exception as e:
        return JSONResponse(content={"error": str(e)}, status_code=500)

@app.post("/gerar-relatorio")
async def gerar_relatorio(payload: dict):
    nome_cliente = payload.get("nome_cliente", "Cliente")
    resultado_classificacao = payload.get("resultado_classificacao")
    genero_cliente = payload.get("genero_cliente")
    data_atendimento = payload.get("data_atendimento", datetime.today().strftime("%d/%m/%Y"))

    if not resultado_classificacao:
        raise HTTPException(status_code=400, detail="Resultado de classifica√ß√£o ausente.")
    if not genero_cliente:
        raise HTTPException(status_code=400, detail="G√™nero do cliente ausente.")

    dados_classificacao = construir_dados_classificacao(resultado_classificacao)
    prompt = gerar_prompt_relatorio(dados_classificacao, nome_cliente, data_atendimento, genero_cliente)

    response = client.chat.completions.create(
        model="gpt-4-turbo",
        messages=[
            {"role": "system", "content": "Voc√™ √© a assistente Lia, sens√≠vel e acolhedora."},
            {"role": "user", "content": prompt}
        ],
        temperature=0.8,
        max_tokens=3000
    )

    raw = response.choices[0].message.content or ""
    match = re.search(r"\{[\s\S]*\}", raw)
    if not match:
        raise HTTPException(status_code=500, detail=f"Falha ao localizar JSON na resposta:\n{raw}")
    cleaned_raw = match.group(0)

    try:
        resultado_json = json.loads(cleaned_raw)
    except json.JSONDecodeError:
        raise HTTPException(status_code=500, detail=f"Erro ao decodificar JSON:\n{cleaned_raw}")

    return {"relatorio": resultado_json}

@app.get("/caracteristicas")
def obter_caracteristicas():
    return {"caracteristicas": CARACTERISTICAS_TEXTO}
